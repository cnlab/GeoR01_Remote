{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM-to-BIDS conversion using `heudiconv` and `singularity`\n",
    "\n",
    "* This notebook creates jobs for each participant and executes them by looping across participants in this notebook or by creating slurm jobs that can be run in parallel on the slurm cluser\n",
    " \n",
    "\n",
    "#### HISTORY\n",
    "\n",
    "* 9/9/21 dcosme - initial code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the DICOM to BIDS conversion for new data using existing config setup\n",
    "\n",
    "* Now we have set up a mapping and edited the `heuristics.py` file we can do dicom2bids conversion with the following Singularity command.\n",
    "\n",
    "* __N.B.__ Make sure the source folder in:\n",
    "   ```\n",
    "   /fmriDataRaw/fmri_data_raw/bbprime\n",
    "   ```\n",
    "\n",
    "* The only thing that needs to be changed is the subject identifier:\n",
    "   ```\n",
    "   -s BPP00\n",
    "   ```\n",
    "   \n",
    "   it should match the folder name of the subject's data in\n",
    "   ```\n",
    "   /fmriDataRaw/fmri_data_raw/bbprime\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through participants\n",
    "The code below creates a job that can be executed in this notebook\n",
    "\n",
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T16:33:20.945490Z",
     "start_time": "2022-06-13T16:33:20.938972Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = 'geoscan_v2'\n",
    "job_dir = os.path.join('/data00/projects/' + project + '/scripts/BIDS/jobs')\n",
    "subs = ['GEO021',\n",
    "        'GEO033',\n",
    "        'GEO036',\n",
    "        'GEO037']\n",
    "\n",
    "job_file_template = r'''#!/bin/bash\n",
    "singularity run --cleanenv \\\n",
    "    -B /data00/projects/geoscan_v2:/base  \\\n",
    "    -B /fmriDataRaw/fmri_data_raw:/raw \\\n",
    "    /data00/tools/singularity_images/heudiconv_0.8.0 \\\n",
    "    -d /raw/geoscan/T2/{subject}_T2/*.dcm \\\n",
    "    -o /base/data/bids_data/ \\\n",
    "    -f /base/scripts/BIDS/heudiconv/code/heuristic.py -ss t2 -s {ID} -c dcm2niix -b --overwrite\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through specified participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-13T16:33:24.284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Creating: GEO021 -------------\n",
      "/data00/projects/geoscan_v2/scripts/BIDS/jobs/heudiconv_GEO021.job\n",
      "INFO: Running heudiconv version 0.8.0 latest 0.11.3\n",
      "INFO: Need to process 1 study sessions\n",
      "INFO: PROCESSING STARTS: {'subject': 'GEO021', 'outdir': '/base/data/bids_data/', 'session': 't2'}\n",
      "INFO: Processing 2603 dicoms\n",
      "INFO: Analyzing 2603 dicoms\n",
      "INFO: Generated sequence info for 11 studies with 2603 entries total\n",
      "INFO: Doing conversion using dcm2niix\n",
      "INFO: Converting /base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w (160 DICOMs) -> /base/data/bids_data/sub-GEO021/ses-t2/anat . Converter: dcm2niix . Output types: ('nii.gz',)\n",
      "220613-12:34:17,649 nipype.utils INFO:\n",
      "\t Running nipype version 1.4.2 (latest: 1.8.1)\n",
      "INFO: Running nipype version 1.4.2 (latest: 1.8.1)\n",
      "220613-12:34:17,654 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"convert\" in \"/tmp/dcm2niixvf1adrdx/convert\".\n",
      "INFO: [Node] Setting-up \"convert\" in \"/tmp/dcm2niixvf1adrdx/convert\".\n",
      "220613-12:34:17,719 nipype.workflow INFO:\n",
      "\t [Node] Running \"convert\" (\"nipype.interfaces.dcm2nii.Dcm2niix\"), a CommandLine Interface with command:\n",
      "dcm2niix -b y -z y -x n -t n -m n -f /base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w -o . -s n -v n /tmp/dcm2niixvf1adrdx/convert\n",
      "INFO: [Node] Running \"convert\" (\"nipype.interfaces.dcm2nii.Dcm2niix\"), a CommandLine Interface with command:\n",
      "dcm2niix -b y -z y -x n -t n -m n -f /base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w -o . -s n -v n /tmp/dcm2niixvf1adrdx/convert\n",
      "220613-12:34:18,228 nipype.interface INFO:\n",
      "\t stdout 2022-06-13T12:34:18.228248:Chris Rorden's dcm2niiX version v1.0.20190410  GCC6.3.0 (64-bit Linux)\n",
      "INFO: stdout 2022-06-13T12:34:18.228248:Chris Rorden's dcm2niiX version v1.0.20190410  GCC6.3.0 (64-bit Linux)\n",
      "220613-12:34:18,228 nipype.interface INFO:\n",
      "\t stdout 2022-06-13T12:34:18.228248:Found 160 DICOM file(s)\n",
      "INFO: stdout 2022-06-13T12:34:18.228248:Found 160 DICOM file(s)\n",
      "220613-12:34:18,228 nipype.interface INFO:\n",
      "\t stdout 2022-06-13T12:34:18.228248:Convert 160 DICOM as ./base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w (192x256x160x1)\n",
      "INFO: stdout 2022-06-13T12:34:18.228248:Convert 160 DICOM as ./base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w (192x256x160x1)\n",
      "220613-12:34:18,600 nipype.interface INFO:\n",
      "\t stdout 2022-06-13T12:34:18.600108:Compress: \"/usr/bin/pigz\" -b 960 -n -f -6 \"./base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w.nii\"\n",
      "INFO: stdout 2022-06-13T12:34:18.600108:Compress: \"/usr/bin/pigz\" -b 960 -n -f -6 \"./base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w.nii\"\n",
      "220613-12:34:18,600 nipype.interface INFO:\n",
      "\t stdout 2022-06-13T12:34:18.600108:Conversion required 0.767427 seconds (0.231870 for core code).\n",
      "INFO: stdout 2022-06-13T12:34:18.600108:Conversion required 0.767427 seconds (0.231870 for core code).\n",
      "220613-12:34:18,634 nipype.workflow INFO:\n",
      "\t [Node] Finished \"convert\".\n",
      "INFO: [Node] Finished \"convert\".\n",
      "WARNING: Failed to find task field in /base/data/bids_data/sub-GEO021/ses-t2/anat/sub-GEO021_ses-t2_T1w.json.\n",
      "220613-12:34:18,892 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"embedder\" in \"/tmp/embedmetaazcti32k/embedder\".\n",
      "INFO: [Node] Setting-up \"embedder\" in \"/tmp/embedmetaazcti32k/embedder\".\n",
      "220613-12:34:18,928 nipype.workflow INFO:\n",
      "\t [Node] Running \"embedder\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "INFO: [Node] Running \"embedder\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    }
   ],
   "source": [
    "# make the job directory if it doens't exist\n",
    "if os.path.exists(job_dir) == False:\n",
    "    os.mkdir(job_dir)\n",
    "\n",
    "# loop over participants\n",
    "for s in subs:\n",
    "    print('-------------- Creating: {} -------------'.format(s))\n",
    "    \n",
    "    file_path = os.path.join(job_dir, 'heudiconv_{}.job').format(s)\n",
    "    print(file_path)\n",
    "\n",
    "    with open(file_path.format(s), 'w') as job:\n",
    "        job.write(job_file_template.format(ID=s, subject='{subject}'))\n",
    "    \n",
    "    !bash $file_path\n",
    "    print('~~~~=====~~~~ Sub {} Completed ~~~~=====~~~~'.format(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit jobs using slurm\n",
    "The code below creates a job that can be run using slurm\n",
    "\n",
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Enter your project name here'\n",
    "project_dir = os.path.join('/data00/projects/', project)\n",
    "slurm_dir = os.path.join(project_dir, 'scripts/BIDS/jobs/heudiconv')\n",
    "os.makedirs(slurm_dir, exist_ok=True)\n",
    "subs = ['']\n",
    "\n",
    "job_file_template = r'''#!/bin/bash\n",
    "#SBATCH --job-name=heudiconv_{ID}.job\n",
    "#SBATCH --output=out/heudiconv_{ID}.out\n",
    "#SBATCH --error=out/heudiconv_{ID}.err\n",
    "#SBATCH --time=02:00\n",
    "\n",
    "srun singularity run --cleanenv \\\n",
    "    -B /data00/projects/{Your Project}:/base  \\\n",
    "    -B /fmriDataRaw/fmri_data_raw:/raw \\\n",
    "    /data00/tools/singularity_images/heudiconv_0.8.0 \\\n",
    "    -d /raw/{Your Project}/{ID}/*/*.dcm \\\n",
    "    -o /base/data/bids_data/ \\\n",
    "    -f heudiconv/code/heuristic.py -s {ID} -c dcm2niix -b --overwrite\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through specified participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in subs:\n",
    "    print('-------------- Creating: {} -------------'.format(s))\n",
    "    \n",
    "    file_path = os.path.join(slurm_dir, 'heudiconv_{}.job').format(s)\n",
    "    print(file_path)\n",
    "\n",
    "    with open(file_path.format(s), 'w') as job:\n",
    "        job.write(job_file_template.format(ID=s, subject='{subject}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule the jobs on slurm\n",
    "\n",
    "Login to the slurm cluster:\n",
    "\n",
    "```\n",
    "ssh <JANUS_UN>@asc.upenn.edu@cls000\n",
    "```\n",
    "\n",
    "This will give you a terminal on the SLURM master node where you can look at the process queue and schedule jobs by pasting the output from the next chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"cd {slurm_dir}\")\n",
    "for s in subs:\n",
    "    print(f\"sbatch -D {slurm_dir} -c 8 heudiconv_{s}.job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data00/slurm_jobs/slurm_bbprime/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
