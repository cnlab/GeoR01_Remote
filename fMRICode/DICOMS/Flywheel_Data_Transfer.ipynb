{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPenn Flywheel Data Transfer to ASC FMRISrv \n",
    "\n",
    "This notebook was shared by Dr Nicole Cooper from CNLab referenced this notebook for Flywheel MURI scan downloads as an example... The same should work for CNLab & AHALab Flywheel projects.\n",
    "\n",
    "+ 02/21/2020 - [José Carreras-Tartak](mailto:jcarreras@falklab.org) original author\n",
    "+ 04/28/2021 - [Etienne Jacquot](mailto:etienne.jacquot@asc.upenn.edu) revisited\n",
    "\n",
    "\n",
    "## *Getting Started w/ [UPenn Flywheel](https://upenn.flywheel.io/) Python-SDK*:\n",
    "\n",
    "The AHA lab does not have a project on Flywheel so maybe not all the steps are exact yet. This eventually will be in place though. For now let us try based on a specific sessionID\n",
    "\n",
    "- Please navigate here for access via Pennkey: https://upenn.flywheel.io/\n",
    "- you need an **api key**, be careful with this secret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:15.553040Z",
     "start_time": "2022-06-12T18:27:15.122103Z"
    }
   },
   "outputs": [],
   "source": [
    "import flywheel\n",
    "import tarfile\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create you Flywheel API secret config file \n",
    "\n",
    "\n",
    "- If the cell below returns True, you have a .config file with an api key of some kind. If it returns false OR if your api key needs to be changed, you can run the cell below that to create your apikey or manually navigate and create your [configs/config.ini](./configs/config.ini) (_we add *.ini to the .gitignore_)\n",
    "\n",
    "\n",
    "\n",
    "_____\n",
    "\n",
    "```python\n",
    "config['UPENN-FLYWHEEL'] = {'apikey':your_api_key}  # <-- define your api key\n",
    "\n",
    "with open(home_dir + '/configs/config.ini', 'w') as configFile: # <-- write to file!\n",
    "    config.write(configFile)\n",
    "\n",
    "```\n",
    "\n",
    "_______\n",
    "\n",
    "### Read Flywheel API secret into Python w/ ConfigParser\n",
    "\n",
    "- You must login and navigate to https://upenn.flywheel.io/#/profile, this has your API key \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:18.896747Z",
     "start_time": "2022-06-12T18:27:18.879780Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API Key exists. If the output is false\n",
    "home_dir = \"/home/aresnick@asc.upenn.edu\"\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(home_dir + \"/configs/config.ini\")\n",
    "config.has_option('UPENN-FLYWHEEL', 'apikey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your home directory where the config file should be saves\n",
    "\n",
    "your_api_key = \"upenn.flywheel.io:YOUR_API_KEY\"\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config['UPENN-FLYWHEEL'] = {'apikey':your_api_key}\n",
    "with open(home_dir + '/configs/config.ini', 'w') as configFile:\n",
    "    config.write(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:22.527074Z",
     "start_time": "2022-06-12T18:27:22.519765Z"
    }
   },
   "outputs": [],
   "source": [
    "# add UPenn Flywheel api key to your config.ini\n",
    "fw_cred = {}\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read(home_dir + '/configs/config.ini') \n",
    "for item,value in config['UPENN-FLYWHEEL'].items():\n",
    "    fw_cred[item]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:23.585833Z",
     "start_time": "2022-06-12T18:27:23.583136Z"
    }
   },
   "outputs": [],
   "source": [
    "# read your API key\n",
    "api = fw_cred['apikey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm your access to Flywheel via python SDK\n",
    "\n",
    "- The `fw.get_current_user()` command is a quick way to ensure you have established a secure connection to UPenn Flywheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:26.063623Z",
     "start_time": "2022-06-12T18:27:26.057851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create client using your API key\n",
    "fw = flywheel.Client(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T20:45:53.609283Z",
     "start_time": "2022-06-12T20:45:53.331525Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPenn Flywheel User: Anthony Resnick (aresni@upenn.edu)\n"
     ]
    }
   ],
   "source": [
    "# print your flywheel information & confirm it works as expected\n",
    "self = fw.get_current_user()\n",
    "print('UPenn Flywheel User: %s %s (%s)' % \n",
    "      (self.firstname, self.lastname, self.email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "## Proceed by Navigating to Flywheel, you'll notice the URL always has respective identifiers\n",
    "\n",
    "In this example, our notebook tests for a known session ID associated w/ Dr Lydon-Staley AHA Lab:\n",
    "\n",
    "- https://upenn.flywheel.io/#/projects/5ba2913fe849c300150d02ed/sessions/6088730ee6de2e3066bd7249\n",
    "    - where the session ID is in the URL --> `6088730ee6de2e3066bd7249`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your Flywheel Project Container & Corresponding Local Out Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-12T18:27:30.779965Z",
     "start_time": "2022-06-12T18:27:30.776659Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace with name of Flywheel project container (i.e. \"geoscan\")\n",
    "# in_project = \"geoscan\"\n",
    "in_project = 'geoscan'\n",
    "\n",
    "# replace with output project folder name in fMRI server (i.e. \"geoscanR01\")\n",
    "# out_project = \"GS\"\n",
    "out_project = \"geoscan_R01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your session specific ID & corresponding out ID\n",
    "\n",
    "- not sure why the `opID` is entirely needed here... TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:20:48.419144Z",
     "start_time": "2022-06-13T04:20:48.414139Z"
    }
   },
   "outputs": [],
   "source": [
    "## MODIFY BELOW\n",
    "# replace with ppt ID as listed on Flywheel (e.g. for geoscan, typically \"gsXXX\")\n",
    "#ipID = \"gs004\"\n",
    "ipID = \"gs032_t2\"\n",
    "\n",
    "# replace with ppt ID as it will be stored in the server (i.e. \"GSXXX\")\n",
    "#opID = \"GS004\"\n",
    "opID = 'GS032_t2' # <--- I think this could be whatever, so long as this is unique on the FMRI host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that output directory in the server is accurate\n",
    "\n",
    "- You may need to create this directory ahead of time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:20:49.532094Z",
     "start_time": "2022-06-13T04:20:49.349662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GS004-T2',\n",
       " 'GS005',\n",
       " 'GS008',\n",
       " 'GS016',\n",
       " 'GS017_t2',\n",
       " 'GS017_t3',\n",
       " 'GS020',\n",
       " 'GS022_t2',\n",
       " 'GS022_t3',\n",
       " 'GS024_t2',\n",
       " 'GS024_t3',\n",
       " 'GS025_t2',\n",
       " 'GS025_t3',\n",
       " 'GS026',\n",
       " 'GS028_t2',\n",
       " 'GS028_t3',\n",
       " 'GS031_t2',\n",
       " 'GS031_t3']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath = '/fmriDataRaw/fmri_data_raw/{PROJECT}'.format(PROJECT=out_project)\n",
    "\n",
    "os.listdir(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "## Proceed with looking up your subject data & downloading Dicom tarball\n",
    "\n",
    "NOTE!!\n",
    "\n",
    "* Location for DICOMS on the server IS:\n",
    "\n",
    "    - `/fmriDataRaw/fmri_data_raw/{PROJECT}/`\n",
    "\n",
    "e.g. untar the appropriate folder to e.g. `/fmriDataRaw/fmri_data_raw/{PROJECT}/`\n",
    "\n",
    "\n",
    "### Flywheel uses `Group / Project / Subject / Session` to identify scan ... \n",
    "\n",
    "- the **group** is `falklab`\n",
    "\n",
    "- the **project** is `bbprime` *(fw://unknown/Unsorted)*\n",
    "\n",
    "- the **subject** is `bpp00` *(probably a default for the unsorted group)*\n",
    "\n",
    "- the **session** is `CAMRIS^Falk`\n",
    "\n",
    "#### Thus our lookup string is --> `'falklab/bbprime/bpp00/CAMRIS^Falk'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:20:50.264671Z",
     "start_time": "2022-06-13T04:20:50.255461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'falklab/geoscan/gs032_t2/CAMRIS^Falk'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group_label = 'falklab'\n",
    "group_label = 'falklab'\n",
    "\n",
    "#project_label = 'bbprime'\n",
    "project_label = in_project # <-- values are set early on in the notebook... maybe that isn't helpful though?\n",
    "\n",
    "#subject_label = 'bpp00'\n",
    "subject_label = ipID # <-- values are set early on in the notebook... maybe that isn't helpful though?\n",
    "\n",
    "session_label = 'CAMRIS^Falk'\n",
    "\n",
    "######################################################\n",
    "\n",
    "lookup_string = '{}/{}/{}/{}'.format(group_label,project_label,subject_label,session_label)\n",
    "lookup_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceed with looking up the known session in the *Unsorted* project\n",
    "\n",
    "Create `session` object to lookup session of interest, you want to then confirm metadata is accurate!\n",
    "\n",
    "- For a helpful video overview on finding your data on Flywheel w/ Python-SDK, I strongly encourage you to visit here:\n",
    "https://docs.flywheel.io/hc/en-us/articles/360048440933-Webinar-Series-Finding-your-stuff-in-Flywheel-with-the-Python-SDK\n",
    "\n",
    "*TODO --> CONTACT UPENN FLYWHEEL ADMIN TEAM TO FIGURE OUT LAB PROJECTS!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:20:51.398234Z",
     "start_time": "2022-06-13T04:20:51.208406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': None,\n",
       " 'analyses': [],\n",
       " 'code': 'gs032_t2',\n",
       " 'cohort': None,\n",
       " 'created': datetime.datetime(2021, 12, 10, 21, 42, 23, 445000, tzinfo=tzutc()),\n",
       " 'ethnicity': None,\n",
       " 'files': [],\n",
       " 'firstname': None,\n",
       " 'id': '61b3c9bf8022190b119f112d',\n",
       " 'info': {},\n",
       " 'info_exists': False,\n",
       " 'label': 'gs032_t2',\n",
       " 'lastname': None,\n",
       " 'master_code': None,\n",
       " 'modified': datetime.datetime(2021, 12, 10, 21, 42, 23, 445000, tzinfo=tzutc()),\n",
       " 'notes': [],\n",
       " 'parents': {'acquisition': None,\n",
       "             'analysis': None,\n",
       "             'group': 'falklab',\n",
       "             'project': '5e2b4677048f71007908099d',\n",
       "             'session': None,\n",
       "             'subject': None},\n",
       " 'permissions': [],\n",
       " 'project': '5e2b4677048f71007908099d',\n",
       " 'race': None,\n",
       " 'revision': 1,\n",
       " 'sex': None,\n",
       " 'species': None,\n",
       " 'strain': None,\n",
       " 'tags': [],\n",
       " 'type': None}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#session = fw.lookup('{}'.format(lookup_string))\n",
    "session = fw.lookup('{group}/{proj}/{pid}'.format(group=group_label,proj=in_project,pid=ipID))\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Flywheel Session tarball to FMRISrv\n",
    "\n",
    "- Once we have the tar zip we can then extract our dicoms to the network\n",
    "\n",
    "\n",
    "- *On running for Dr Lydon-Staley test subject, this tarball file is nearly 1GB*\n",
    "\n",
    "#### What about the `./working_data` directory? \n",
    "\n",
    "*TODO --> Where does working data directory go? Is that just in the jupyterhub environment? does the tarball get deleted after or saved to the network in raw data?* \n",
    "*working data is still here! -AR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:20:52.572648Z",
     "start_time": "2022-06-13T04:20:52.427700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘working_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir working_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:21:02.112747Z",
     "start_time": "2022-06-13T04:20:52.660987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_cnt': 18,\n",
       " 'size': 364023217,\n",
       " 'ticket': '50f57c6f-bf95-4a41-bdab-c420261a5817'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw.download_tar(session,'./working_data/{opID}.tar'.format(opID=opID))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract contents of Flywheel tar download:\n",
    "\n",
    "In the following cells, you will:\n",
    "\n",
    "1. Load tarball into jupyterhub notebook memory space\n",
    "\n",
    "2. Set your dicom out directory and confirm permissions\n",
    "\n",
    "3. Loop through tarball `.getmembers()` and then extract zipped dicoms\n",
    "\n",
    "### Load into Memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:22:04.750938Z",
     "start_time": "2022-06-13T04:22:04.678659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening tar in memory as: <_io.BufferedReader name='working_data/GS032_t2.tar'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"working_data/{opID}.tar\".format(opID=opID), 'rb') # <--- Flywheel download as Read Bytes\n",
    "print ('Opening tar in memory as:',f,'\\n')\n",
    "tar_data = tarfile.open(fileobj=f, mode='r:') # <--- Unpack tar in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and Create your Out Directory:\n",
    "\n",
    "- Jupyterhub does not respect secondary group permissions... so when I create a directory it's default to FMRISrvUser1@asc.upenn.edu instead of FMRISrvAHAUsers@asc.upenn.edu ... will manually correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:22:06.304561Z",
     "start_time": "2022-06-13T04:22:06.300627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fmriDataRaw/fmri_data_raw/geoscan_R01/GS032_t2/\n"
     ]
    }
   ],
   "source": [
    "output_dicom_dir = '{outpath}/{opID}/'.format(outpath=outpath,opID=opID)\n",
    "print(output_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:22:06.813446Z",
     "start_time": "2022-06-13T04:22:06.660555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "makedirs --> /fmriDataRaw/fmri_data_raw/geoscan_R01/GS032_t2/\n"
     ]
    }
   ],
   "source": [
    "# Create the directory if not exist\n",
    "if not os.path.exists(os.path.dirname(output_dicom_dir)):\n",
    "    try:\n",
    "        print('makedirs --> {}'.format(output_dicom_dir))\n",
    "        os.makedirs(os.path.dirname(output_dicom_dir))\n",
    "    except:\n",
    "        print('oops! failed to create --> {}'.format(output_dicom_dir))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm permissions for out directory\n",
    "\n",
    "### Had to make the outdir permission 777 -R\n",
    "\n",
    "- Secondary group permission is not respected in jhub so I had to manually change for my user created folder ... \n",
    "\n",
    "```bash\n",
    "sudo chgrp fmrisrvahausers@asc.upenn.edu -R /AHAData/fmri_data_raw/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:22:08.291495Z",
     "start_time": "2022-06-13T04:22:08.163808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxrwxr-x. 1 aresnick@asc.upenn.edu fmrisrv1users@asc.upenn.edu 0 Jun 13 00:22 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxrwxr-x. 1 mbod@asc.upenn.edu     fmrisrv1users@asc.upenn.edu 0 Jun 13 00:22 \u001b[01;34m..\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -la $output_dicom_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT YOUR TARBALL DICOM TO FMRISRV NETWORK STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T04:24:33.367418Z",
     "start_time": "2022-06-13T04:22:09.501403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/localizer_multislice/1.3.12.2.1107.5.2.43.66044.2021121016341149480017035.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/AAHead_Scout/1.3.12.2.1107.5.2.43.66044.202112101635131792317842.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/AAHead_Scout_MPR_sag/1.3.12.2.1107.5.2.43.66044.2021121016351663816618885.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/AAHead_Scout_MPR_cor/1.3.12.2.1107.5.2.43.66044.2021121016351663861118891.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/AAHead_Scout_MPR_tra/1.3.12.2.1107.5.2.43.66044.2021121016351663884218895.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/PhoenixZIPReport/1.3.12.2.1107.5.2.43.66044.30000021120923390393900000156.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/BOLD_IMAGE_run01/1.3.12.2.1107.5.2.43.66044.202112101641469447219431.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/FieldMap_PA/1.3.12.2.1107.5.2.43.66044.2021121016491321361237916.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/BOLD_IMAGE_run02/1.3.12.2.1107.5.2.43.66044.2021121016493416866438481.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/FieldMap_PA_0/1.3.12.2.1107.5.2.43.66044.2021121016570577909756966.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/BOLD_IMAGE_run03/1.3.12.2.1107.5.2.43.66044.2021121016572677281957531.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/FieldMap_PA_1/1.3.12.2.1107.5.2.43.66044.2021121017044020514176016.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/BOLD_IMAGE_run04/1.3.12.2.1107.5.2.43.66044.2021121017050117491376581.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/FieldMap_PA_2/1.3.12.2.1107.5.2.43.66044.2021121017115467198195066.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/BOLD_IMAGE_run05/1.3.12.2.1107.5.2.43.66044.2021121017121570961995631.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/FieldMap_PA_3/1.3.12.2.1107.5.2.43.66044.2021121017193320720214116.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/T2_1mm_SPACE/1.3.12.2.1107.5.2.43.66044.2021121017244710697114920.0.0.0.dicom.zip\n",
      "\n",
      "Extracting: scitran/falklab/geoscan/gs032_t2/CAMRIS^Falk/MPRAGE_TI1100_ipat2/1.3.12.2.1107.5.2.43.66044.2021121017250961432815872.0.0.0.dicom.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for member in tar_data.getmembers():\n",
    "    \n",
    "    if 'dicom.zip' in member.name:       # <--- Only extract files with 'dicom.zip' \n",
    "        \n",
    "        print('Extracting: {}\\n'.format(member.name))\n",
    "        \n",
    "        tfile = tar_data.extractfile(member.name)\n",
    "        dicom_zip = zipfile.ZipFile(tfile, mode='r')\n",
    "        dicom_zip.extractall(output_dicom_dir)\n",
    "tar_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have now successfully downloaded the dicom data from Flywheel to ASC servers\n",
    "\n",
    "- this goes to `/fmriDataRaw/fmri_data_raw/bbprime/BPP00/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T03:36:23.885646Z",
     "start_time": "2022-06-13T03:36:23.739062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.3.12.2.1107.5.2.43.66044.2021112911041388531815681.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911051530623416431.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911051894533717531.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911051894574117537.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911051894597717541.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911075572401018076.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911115081901019205.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911183849813537690.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911190368805938255.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911263612666656740.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.202111291126576452957305.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911340233718875790.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911342331441676355.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.202111291141346549894840.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911415510279695405.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911485044091313890.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911543486350114693.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.2021112911545697094715646.0.0.0.dicom',\n",
       " '1.3.12.2.1107.5.2.43.66044.30000021112223285831800000162.dicom']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('{}'.format(output_dicom_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete .tar files?\n",
    "\n",
    "If you would like to delete the .tar files, open the terminal, navigate to this directory, and enter the following code to recursively empty the .tar folder. You can either keep these or download them again as needed from flywheel. *BE CAREFUL* Make sure you are pointing to the correct directory! This will recursively delete every file in a directory!\n",
    "\n",
    "```python\n",
    "rm -r [path/to/DICOMS/working_data/]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
